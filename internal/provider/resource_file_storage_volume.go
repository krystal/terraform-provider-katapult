package provider

import (
	"context"
	"errors"
	"strings"
	"time"

	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/krystal/go-katapult"
	"github.com/krystal/go-katapult/core"
)

func resourceFileStorageVolume() *schema.Resource {
	return &schema.Resource{
		CreateContext: resourceFileStorageVolumeCreate,
		ReadContext:   resourceFileStorageVolumeRead,
		UpdateContext: resourceFileStorageVolumeUpdate,
		DeleteContext: resourceFileStorageVolumeDelete,
		Timeouts: &schema.ResourceTimeout{
			Create: schema.DefaultTimeout(1 * time.Minute),
			Delete: schema.DefaultTimeout(1 * time.Minute),
			Update: schema.DefaultTimeout(1 * time.Minute),
		},
		Importer: &schema.ResourceImporter{
			StateContext: schema.ImportStatePassthroughContext,
		},
		//nolint:lll
		Description: strings.TrimSpace(`

The File Storage Volume resource allows you to manage File Storage Volumes in Katapult.

-> **Note:** Volumes are not automatically mounted within associated virtual machines. This must be done manually or via a provisioning tool of some kind, using the ` + "`nfs_location`" + ` attribute value as the mount source.

~> **Warning:** Deleting a file storage volume resource with Terraform will by default purge the volume from Katapult's trash, permanently deleting it. If you wish to instead keep a deleted volume in the trash, set the` + "`skip_trash_object_purge`" + ` provider option to ` + "`true`" + `. By default, objects in the trash are permanently deleted after 48 hours.

`,
		),
		Schema: map[string]*schema.Schema{
			"id": {
				Type:     schema.TypeString,
				Computed: true,
				Description: "The ID of the file storage volume. This is " +
					"automatically generated by the API.",
			},
			"name": {
				Type:     schema.TypeString,
				Required: true,
				Description: "Unique name to help identify the volume. " +
					"Must be unique within the organization.",
				ValidateFunc: validation.StringIsNotEmpty,
			},
			"associations": {
				Type:     schema.TypeSet,
				Optional: true,
				Description: "The resource IDs which can access this file " +
					"storage volume. Currently only accepts virtual " +
					"machine IDs.",
				Elem: &schema.Schema{
					Type:         schema.TypeString,
					ValidateFunc: validation.StringIsNotEmpty,
				},
			},
			"nfs_location": {
				Type:     schema.TypeString,
				Computed: true,
				Description: "The NFS location indicating where to mount the " +
					"volume from. This is where the volume must be mounted " +
					"from inside of virtual machines referenced in " +
					"`associations`.",
			},
		},
	}
}

func resourceFileStorageVolumeCreate(
	ctx context.Context,
	d *schema.ResourceData,
	meta interface{},
) diag.Diagnostics {
	m := meta.(*Meta)

	args := &core.FileStorageVolumeCreateArguments{
		Name:       d.Get("name").(string),
		DataCenter: m.DataCenterRef,
		Associations: schemaSetToSlice[string](
			d.Get("associations").(*schema.Set),
		),
	}

	fsv, _, err := m.Core.FileStorageVolumes.Create(
		ctx, m.OrganizationRef, args,
	)
	if err != nil {
		return diag.FromErr(err)
	}

	fsv, err = waitForFileStorageVolumeToBeReady(
		ctx, m, d.Timeout(schema.TimeoutCreate), 2*time.Second, fsv.Ref(),
	)
	if err != nil {
		return diag.Diagnostics{
			{
				Severity: diag.Error,
				Summary: "Error waiting for file storage volume to " +
					"become ready.",
				Detail: err.Error(),
			},
		}
	}

	d.SetId(fsv.ID)

	return resourceFileStorageVolumeRead(ctx, d, m)
}

func resourceFileStorageVolumeRead(
	ctx context.Context,
	d *schema.ResourceData,
	meta interface{},
) diag.Diagnostics {
	m := meta.(*Meta)
	var diags diag.Diagnostics

	fsv, _, err := m.Core.FileStorageVolumes.GetByID(ctx, d.Id())
	if err != nil {
		if errors.Is(err, katapult.ErrNotFound) {
			d.SetId("")

			return diags
		}

		return diag.FromErr(err)
	}

	_ = d.Set("name", fsv.Name)
	_ = d.Set("nfs_location", fsv.NFSLocation)

	err = d.Set("associations", stringSliceToSchemaSet(fsv.Associations))
	if err != nil {
		diags = append(diags, diag.FromErr(err)...)
	}

	return diags
}

func resourceFileStorageVolumeUpdate(
	ctx context.Context,
	d *schema.ResourceData,
	meta interface{},
) diag.Diagnostics {
	m := meta.(*Meta)

	id := d.Id()
	ref := core.FileStorageVolumeRef{ID: id}
	args := &core.FileStorageVolumeUpdateArguments{}

	if d.HasChange("name") {
		args.Name = d.Get("name").(string)
	}

	if d.HasChange("associations") {
		assocs := schemaSetToSlice[string](
			d.Get("associations").(*schema.Set),
		)

		args.Associations = &assocs
	}

	fsv, _, err := m.Core.FileStorageVolumes.Update(ctx, ref, args)
	if err != nil {
		return diag.FromErr(err)
	}

	_, err = waitForFileStorageVolumeToBeReady(
		ctx, m, d.Timeout(schema.TimeoutUpdate), 5*time.Second, fsv.Ref(),
	)
	if err != nil {
		return diag.Diagnostics{
			{
				Severity: diag.Error,
				Summary: "Error waiting for file storage volume to " +
					"become ready.",
				Detail: err.Error(),
			},
		}
	}

	return resourceFileStorageVolumeRead(ctx, d, m)
}

func resourceFileStorageVolumeDelete(
	ctx context.Context,
	d *schema.ResourceData,
	meta interface{},
) diag.Diagnostics {
	m := meta.(*Meta)
	diags := diag.Diagnostics{}

	fsv, _, err := m.Core.FileStorageVolumes.GetByID(ctx, d.Id())
	if err != nil {
		if errors.Is(err, katapult.ErrNotFound) {
			return diags
		} else if errors.Is(err, core.ErrObjectInTrash) {
			if m.SkipTrashObjectPurge {
				return diags
			}

			err2 := purgeTrashObjectByObjectID(
				ctx, m, d.Timeout(schema.TimeoutDelete), fsv.ID,
			)
			if err2 != nil {
				return append(diags, diag.Diagnostic{
					Severity: diag.Error,
					Summary:  "Failed to purge file storage volume from trash.",
					Detail:   err2.Error(),
				})
			}

			return diags
		}

		return append(diags, diag.Diagnostic{
			Severity: diag.Error,
			Summary:  "Failed to lookup file storage volume details.",
			Detail:   err.Error(),
		})
	}

	// If we're skipping purge, we rename the file storage volume before
	// deletion to include its ID. This allows it to be easily identified in the
	// trash, and also avoids name conflicts if another volume is created with
	// the same name.
	if m.SkipTrashObjectPurge {
		// Append the ID to the end of the name, if it's not already there. If
		// the resulting name would be too long, truncate name to fit once the
		// ID is appended.
		name := fsv.Name
		suffix := "-" + fsv.ID
		if !strings.HasSuffix(name, suffix) {
			if len(name)+len(suffix) > 128 {
				name = name[:128-len(suffix)]
			}
			name += suffix
		}

		_, _, err = m.Core.FileStorageVolumes.Update(
			ctx, fsv.Ref(),
			&core.FileStorageVolumeUpdateArguments{Name: name},
		)
		if err != nil && !isErrNotFoundOrInTrash(err) {
			return append(diags, diag.Diagnostic{
				Severity: diag.Error,
				Summary: "Failed to rename file storage volume before " +
					"moving to trash.",
				Detail: err.Error(),
			})
		}
	}

	_, _, _, err = m.Core.FileStorageVolumes.Delete(ctx, fsv.Ref())
	if err != nil && !isErrNotFoundOrInTrash(err) {
		return diag.FromErr(err)
	}

	if !m.SkipTrashObjectPurge {
		err = purgeTrashObjectByObjectID(
			ctx, m, d.Timeout(schema.TimeoutDelete), fsv.ID,
		)
		if err != nil {
			return append(diags, diag.Diagnostic{
				Severity: diag.Error,
				Summary:  "Failed to purge file storage volume from trash.",
				Detail:   err.Error(),
			})
		}
	}

	return diags
}

func waitForFileStorageVolumeToBeReady(
	ctx context.Context,
	m *Meta,
	timeout time.Duration,
	delay time.Duration,
	ref core.FileStorageVolumeRef,
) (*core.FileStorageVolume, error) {
	waiter := &retry.StateChangeConf{
		Pending: []string{
			string(core.FileStorageVolumePending),
			string(core.FileStorageVolumeConfiguring),
		},
		Target: []string{
			string(core.FileStorageVolumeReady),
		},
		Refresh: func() (interface{}, string, error) {
			f, _, err := m.Core.FileStorageVolumes.Get(ctx, ref)
			if err != nil {
				return f, "", err
			}

			return f, string(f.State), nil
		},
		Timeout:                   timeout,
		Delay:                     delay,
		MinTimeout:                5 * time.Second,
		ContinuousTargetOccurence: 1,
	}

	readyFSV, err := waiter.WaitForStateContext(ctx)

	return readyFSV.(*core.FileStorageVolume), err
}
